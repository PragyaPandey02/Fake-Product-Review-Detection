{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# ðŸ§  Fake Product Review Detection using ML Algorithms\n", "This notebook walks through a full machine learning pipeline to detect fake product reviews using NLP and various classification algorithms."]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import re\n", "import string\n", "import nltk\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from nltk.tokenize import word_tokenize\n", "from nltk.stem import WordNetLemmatizer\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n"]}, {"cell_type": "code", "metadata": {}, "source": ["nltk.download("punkt")\n", "nltk.download("wordnet")"]}, {"cell_type": "code", "metadata": {}, "source": ["from google.colab import files\n", "uploaded = files.upload()\n", "\n", "# Load dataset\n", "df = pd.read_csv("dataset.csv")\n", "df.head()"]}, {"cell_type": "code", "metadata": {}, "source": ["def clean_text(text):\n", "    text = str(text).lower()\n", "    text = re.sub(r"\\[.*?\\]", "", text)\n", "    text = re.sub(r"https?://\\S+|www\\.\\S+", "", text)\n", "    text = re.sub(r"<.*?>+", "", text)\n", "    text = re.sub(r"[%s]" % re.escape(string.punctuation), "", text)\n", "    text = re.sub(r"\\n", "", text)\n", "    text = re.sub(r"\\w*\\d\\w*", "", text)\n", "    return text\n", "\n", "lemmatizer = WordNetLemmatizer()\n", "def lemmatize_text(text):\n", "    tokens = word_tokenize(text)\n", "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n", "    return " ".join(lemmatized)\n", "\n", "# Apply cleaning and lemmatization\n", "df["cleaned_review"] = df["review"].apply(clean_text).apply(lemmatize_text)\n", "df[["review", "cleaned_review"]].head()"]}, {"cell_type": "code", "metadata": {}, "source": ["X = df["cleaned_review"]\n", "y = df["label"]\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "metadata": {}, "source": ["models = {\n", "    "SVM": SVC(probability=True),\n", "    "Random Forest": RandomForestClassifier(),\n", "    "Naive Bayes": MultinomialNB(),\n", "    "SGD": SGDClassifier(loss="log_loss", max_iter=1000, tol=1e-3, random_state=42)\n", "}\n", "\n", "results = {}\n", "\n", "for name, model in models.items():\n", "    print(f"\\n=== Training {name} ===")\n", "    pipeline = Pipeline([\n", "        ("tfidf", TfidfVectorizer(max_features=5000)),\n", "        ("clf", model)\n", "    ])\n", "    \n", "    pipeline.fit(X_train, y_train)\n", "    y_pred = pipeline.predict(X_test)\n", "    \n", "    accuracy = accuracy_score(y_test, y_pred)\n", "    report = classification_report(y_test, y_pred, output_dict=True)\n", "    \n", "    try:\n", "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n", "        auc = roc_auc_score(y_test, y_proba)\n", "    except:\n", "        auc = None\n", "\n", "    print(f"Accuracy: {accuracy:.4f}")\n", "    print(f"AUC: {auc:.4f}" if auc else "AUC: Not available")\n", "    print("Classification Report:\\n", classification_report(y_test, y_pred))\n", "    \n", "    results[name] = {\n", "        "model": pipeline,\n", "        "accuracy": accuracy,\n", "        "auc": auc,\n", "        "report": report,\n", "        "confusion_matrix": confusion_matrix(y_test, y_pred)\n", "    }"]}, {"cell_type": "code", "metadata": {}, "source": ["for name, res in results.items():\n", "    cm = res["confusion_matrix"]\n", "    plt.figure(figsize=(4, 3))\n", "    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")\n", "    plt.title(f"Confusion Matrix - {name}")\n", "    plt.xlabel("Predicted")\n", "    plt.ylabel("Actual")\n", "    plt.tight_layout()\n", "    plt.show()"]}, {"cell_type": "code", "metadata": {}, "source": ["model_names = list(results.keys())\n", "accuracies = [results[m]["accuracy"] for m in model_names]\n", "\n", "plt.figure(figsize=(6, 4))\n", "sns.barplot(x=model_names, y=accuracies)\n", "plt.title("Model Accuracy Comparison")\n", "plt.ylabel("Accuracy")\n", "plt.ylim(0, 1)\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}